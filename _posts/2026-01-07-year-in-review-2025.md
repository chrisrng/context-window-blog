---
layout: post
title: On the various "Year In Review 2025" blogs
---

**From https://snscratchpad.com/posts/looking-ahead-2026/**

> "What matters is not the power of any given [LLM] model, but how people choose to apply it to achieve their goals."

This aligns with what I’ve observed, people who use these tools continue to reap their benefits and apply them effectively toward their goals, provided they avoid getting distracted by constant tinkering. Those who were unwilling, or unable, to try them were not swayed by the availability of more powerful models.

> "humans being equipped with these new cognitive amplifier tools as we relate to each other [is] the product design question we need to debate and answer"

There's been a lot of literature on agent-to-agent communications and MCP but very few discussions (and solutions) on how humans talk to each other in a post-LLM world. IRL, we don't assume people are using LLMs for their day-to-day life unlike Web 2.0 products like maps or search. Maybe we need a GUI for LLMs to democratize access or maybe it'll just take more time for the world to evolve like how we still have paper forms vs digital forms vs docusign, etc.

> "For AI to have societal permission it must have real world eval impact."

If we think about coding agents, software engineers didn't start using them because they saw it score well on SWE-bench. We all started using it because when we tried it for our own use cases, it worked. Eval data has been the issue in making world-class AI-native applications. Choosing how to eval (ideally closer to real world use cases) and how to interpret those results (both positive and negative) will meaningfully shift the public buy-in from tech execs to fund a project all the way to a family member using ChatGPT.

**From https://karpathy.bearblog.dev/year-in-review-2025/**

> "By training LLMs against automatically verifiable rewards across a number of environments (e.g. think math/code puzzles), the LLMs spontaneously develop strategies that look like "reasoning" to humans - they learn to break down problem solving into intermediate calculations and they learn a number of problem solving strategies for going back and forth to figure things out (see DeepSeek R1 paper for examples)."
>
> 
> "[LLMs] are at the same time a genius polymath and a confused and cognitively challenged grade schooler, seconds away from getting tricked by a jailbreak to exfiltrate your data"
>
> 
> "Training on the test set is a new art form."

How you evaluate AI-native applications and where you get your eval data becomes it's competitive defensible edge but also its Achilles' heel since it one-shots if your application works or not in the eyes of the user. Is there _magic_ or not?

> "Will the LLM labs capture all applications or are there green pastures for LLM apps [like Cursor]?"

We're back to the thick client vs thin client debate (I still remember doing tests on verifying a Blackberry thin client migration!) but as we saw with single-page applications it's more of a hybrid solution moving forward.

> "Claude Code (CC) emerged as the first convincing demonstration of what an LLM Agent looks like [...] Anthropic got this order of precedence correct and packaged CC into a delightful, minimal CLI form factor that changed what AI looks like - it's not just a website you go to like Google, it's a little spirit/ghost that "lives" on your computer. This is a new, distinct paradigm of interaction with an AI."

> "not only does vibe coding empower regular people to approach programming, it empowers trained professionals to write a lot more (vibe coded) software that would otherwise never be written [...] code is suddenly free, ephemeral, malleable, discardable after single use"

I still haven't seen ephemeral software used as often to solve JIT problems. This will be 

> "[On Nano banana being the first hint of an LLM GUI] in terms of the UIUX, "chatting" with LLMs is a bit like issuing commands to a computer console in the 1980s. Text is the raw/favored data representation for computers (and LLMs), but it is not the favored format for people, especially at the input. People actually dislike reading text - it is slow and effortful. Instead, people love to consume information visually and spatially and this is why the GUI has been invented in traditional computing. In the same way, LLMs should speak to us in our favored format - in images, infographics, slides, whiteboards, animations/videos, web apps, etc.

It's been more than 3 years since ChatGPT released and we're still largely using chatbots either from Web, App, or CLI to interact with LLMs. There's some speech-based UIs and hardware but largely people are still using chatbots. More importantly, we're still receiving data as text instead of structured visual response in a consumable format. With all the focus on creating and serving better models, this area of research has been lagging behind and is an area we can really move the needle in terms of making decisions easier for people harnessing large amounts of data, understanding, and responses from the LLM.

--

... and finally we have the [Pantone Color of the Year 2026](https://www.pantone.com/color-of-the-year/2026) – <span style="color: #f0eee9; padding: 5px">Cloud Dancer</span>!
